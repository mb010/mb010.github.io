---
layout: single
author_profile: true
title: Research
subtitle: Why, What? What??
url: /research/
header:
  image: /assets/images/MeerKAT_composite.jpg
  caption: "Credits: South African Radio Astronomy Observatory (SARAO), Image by Alan Warburton / Â© BBC / Better Images of AI / Plant / CC-BY 4.0"
toc: true
toc_label: "Research Overview"
toc_icon: "fas fa-satellite-dish"
---
My research tends towards deep learning (AI),
radio astronomical imaging, and astronomy beyond the milky way.
I am funded through the STFC's
[4IR CDT](https://www.hep.manchester.ac.uk/u/dprice/4IR-CDT.html) and
[the Alan Turing Institute](https://www.turing.ac.uk/).

# Motivation
Astronomy has been driven by the understanding of data from its conception as a tool for navigation and agriculture through to the 21<sup>st</sup> century. In modern astronomy, the expanse of the universe allows us to probe the most extreme environments in existence to help us garner a better understanding of ...  well pretty much everything.

With enormous volumes of data being generated by the newest astronomical instruments and even more data expected from instruments being built, this is truly the era of big (and I mean big big) data astronomy.

And that's where my research comes in.

# AI & Data science
The term AI is shrouded in both unrealised dreams and nightmares of artificial general intelligence and a singularity. Here I am using the term to encapsulate the various statistical methods which I apply and research which allow the computer to learn from the data we provide it.

I research these methods to combat and extract scientific value from the overwhelming volumes of data which modern astronomical instruments produce.

## AI Research
Specifically, my research thus far has focussed on the properties of *supervised deep learning self-attention computer vision models* to help classify the large volumes of radio astronomy data which is expected to be produced over the coming years.

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/uamO7y_zRbg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/vk0nr9iggdk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
<cite style="font-size:small">Self-attention maps of models trained to classify radio galaxies. See: [Bowles et al. (2021)](https://arxiv.org/abs/2111.04742).</cite>

Within the field of machine learning (ML), I am interested in a broad range of concepts including computer vision and explainable AI. I aim to expand my research to both match my growing interests and benefit the astronomical community.

## Citizen Science and EMU Zoo
For those of you wondering how we can use deep learning methodologies for astronomy when they rely on many labels of data points, you are justified in your concern. However, there are currently at least two answers to your concerns.

Firstly, astronomers have been labelling objects for several decades which can give us enough labels to work with in some cases. Secondly, we can learn to make use of so-called *citizen scientists*. These are people who look at samples of data and provide information on the sample in a fashion which is easy for a human to do, but traditionally impossible for a computer. This concept has been used for many different projects and will be a useful tool in many fields going forwards. My thanks to the citizen scientists working on any project! The portal I am most familiar with, and has been used extensively in astronomy, is [zooniverse](https://www.zooniverse.org/) which hosts projects in a wide variety of domains from art to climate science to astronomy.

I am part of the team led by Hongming Tang and Eleni Vardoulaki working to bring the citizen science project [EMU-Zoo](https://www.zooniverse.org/projects/hongming-tang/radio-galaxy-zoo-emu/) to life. This project will provide us with better insight into the droves of data being produced by the [EMU survey](http://emu-survey.org/), and more broadly inform future research in the field of radio astronomy.

![EMU-Zoo Logo](/assets/images/EMUZoo_logo.jpeg)
\
<cite style="font-size:small">[EMU Zoo Logo](https://www.zooniverse.org/projects/hongming-tang/radio-galaxy-zoo-emu/)</cite>


# Radio Astronomy
So we have our labels and our fancy statistics but where does the actual science image come from? A simple combination of: incredible instrumentation, masterful mathematics and considerable computation.

## Instrumentation
The largest limitation of radio telescopes is the diameter of the receiving area and the total collecting area. The three largest steerable radio telescopes are the [Lovell Telescope](https://www.jodrellbank.net/visit/whats-here/lovell-telescope/) at 76m, [Effelsberg](https://www.mpifr-bonn.mpg.de/en/effelsberg) at 100m and [Green Bank Telescope](https://greenbankobservatory.org/science/telescopes/gbt/) at 100m. The reason we don't build bigger is: we can't. Any bigger and the structure would bend and bow under it's own weight.

The scientific community has found two complementary solutions to this: either build a single dish in an existing natural structure such as a valley (see the late [Arecibo Telescope](https://en.wikipedia.org/wiki/Arecibo_Observatory) or [FAST](https://fast.bao.ac.cn/)), or build a number of smaller telescopes and synthesise an incredible single larger telescope by combining their signals. This telescope synthesis is known as **interferometry** and is used to synthesise telescopes with much larger effective diameters. This increased size comes at the cost of reduced collecting area in comparison to a full dish of the same size (which cannot exist in our current paradigm).

I process the data collected by an interferometric array into useful scientific data products. Specifically I work on data from [MeerKAT](https://en.wikipedia.org/wiki/MeerKAT) whose anntenna are depicted in the banner image at the top of this page.

## Mathematics
Without repeating the beautiful and masterful mathematics around synthesising an image from the raw 'visibilities' collected by the array, the process is (much simplified) into calibration of the data, flagging erroneous data and transforming the data into an image.

The transformation of the data into an image is sketched out below.
\
![Pretty interferometric imaging](/assets/images/Interferometry_Research.jpg)
\
<cite style="font-size:small">Cartoon schematic of interferometric imaging. FT = Fourrier Transforms. And no, they aren't real.</cite>

My colleagues made me promise to point out that this is a severe simplification: I'm skipping critical steps in scientific imaging as well as the majority of the calculations that likely don't add much value to the experience of a non-expert reader. Reach out for resources to the real meat of interferometric imaging.

## Computation
Considerable copmutation is required to image radio interferometric data at scale. Time for some napkin calculations: The MeerKAT array has up to 32,000 channels, 64 antenna meaning 2,018 baselines, and 4 polarisation products per baseline. Each pointing consists of 8 hours of observations with 8 second intervals. This amounts to: 32000*2018*4*6/(8/60<sup>2</sup>)=6.97 x 10<sup>9</sup> data points. At 64 bits per data point, each pointing amounts to approximately 45 TB.

We deal with this in a number of ways. After reducing the data to whatever is required by the respective team, the data can be processed using specialised software which we write for specialised hardware. Using high performance computing facilities such as these is non-trivial and is an area of growth in radio astronomy as newer interferometric facilities such as MeerKAT and eventually the SKAO telescopes require leading technical infrastructure to process the data from the respective instruments. For my work, I make use of IDIA's [ILIFU cluster](https://www.ilifu.ac.za/), specialised high memory [IRIS](https://www.iris.ac.uk/) nodes, and an HPC facility in my department at JBCA.

Finally, within MeerKAT's MIGHTEE survey, the data is reduced in science goal specific ways to allow for individual science products to be realised. Each of the science working groups is listed along side the respective chairs [here](https://www.mighteesurvey.org/team). My work falls within the *MIGHTEE Polarisation* project.

## MIGHTEE-POL
Within the MIGHTEE-POL team, our data is reduced before we receive it to 1k channels, meaning each pointing is ~1.4 TB. We aim to process this into scientifically valuable data products which through the measurements of the polarisation property of the observed radio emission will provide insights into the magnetic properties of our universe. Specifically, we can constrain the magnetic fields of the objects within our fields as well as the magnetic properties of the materials between our telescope and the objects in the four MIGHTEE target fields.

![MIGHTEE XMMLSS Continuum Image](/assets/images/XMM.jpg)
\
<cite style="font-size:small">[Heywood et al. (2021)](https://arxiv.org/abs/2110.00347) figure 3 presents the early science XMMLSS field.</cite>

The science products we produce will be released to the public according to the MIGHTEE guidelines. For more information please see the [MIGHTEE website](https://www.mighteesurvey.org/home). As our work is published I hope to share more details here.

# ML Clubs & AI Ethics
In light of my interests, in collaboration with Dr. Alex Clarke and Dr. Philippa Hartley at the [SKAO](https://www.skatelescope.org/) I organise the SKAO-JBCA ML Club. We run this to share ideas and build collaborations. Please see our club's [website](https://jbca-machinelearning.github.io/) for more details on previous sessions and related activity.

I also developed an ML interest group as a collaboration with the astronomy department (DOA) at [Tsinghua University](https://www.tsinghua.edu.cn/en/). As part of the planning, our committee discussed and developed an ethics statement for ML interest groups to help spread awareness of potential miss-use of ML and to remind participants to be weary of the potential applications of their current and future work. Attempting to encourage each individual to deeply consider what they *should* do over what they *can*. To this end, I developed the clear short reminder:

> In awareness of ongoing misuse of ML around the world, as a community of participants we commit to practising ethical ML. We will strive to consider our impact on all communities, whether through intentional abuse, or through unintended consequences or biases.

 We encouraged our participants to also adhere to, and be aware of, the [NeurIPS ethics guidelines](https://nips.cc/public/EthicsGuidelines) as well as the [SKAO Code of Conduct](https://www.skatelescope.org/ska-organisation/ska-organisation-code-of-conduct-for-meetings/) as more comprehensive guidelines.
